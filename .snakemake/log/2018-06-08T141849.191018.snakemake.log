Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	metaphlan
	2

rule metaphlan:
    input: test-kneaddata-output, test-kneaddata-output/demo_kneaddata.fastq
    output: metaphlan_analysis
    jobid: 1

Skipped removing non-empty directory metaphlan_analysis
    Error in rule metaphlan:
        jobid: 1
        output: metaphlan_analysis

RuleException:
CalledProcessError in line 51 of /home/j/jmoreno8/dev/usf-hii/biobakery/Snakefile:
Command ' set -euo pipefail;  
        /shares/hii/sw/singularity/latest/bin/singularity exec --bind /shares:/shares /shares/hii/images/morenoj/biobakery_image/test.simg python3 ./biobakery-metaphlan2-e7761e78f362/metaphlan2.py test-kneaddata-output/demo_kneaddata.fastq             --input_type fastq             --bowtie2_exe /shares/hii/sw/bowtie2/2.2.9/bin/bowtie2             --bowtie2_build /shares/hii/sw/bowtie2/2.2.9/bin/bowtie2-build             --output metaphlan_analysis ' returned non-zero exit status 1.
  File "/home/j/jmoreno8/dev/usf-hii/biobakery/Snakefile", line 51, in __rule_metaphlan
  File "/shares/hii/sw/snakemake/5.1.2/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Removing output files of failed job metaphlan since they might be corrupted:
metaphlan_analysis
Skipped removing non-empty directory metaphlan_analysis
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/j/jmoreno8/dev/usf-hii/biobakery/.snakemake/log/2018-06-08T141849.191018.snakemake.log
